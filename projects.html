<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <!--
        Arinah Karim
        INFO-I 360 FA22
        Portfolio Final
    -->
    <title>Projects</title>
    <!-- resets browser defaults -->
    <link rel="stylesheet" type="text/css" href="css/normalize.css">
    <!-- custom styles -->
    <link rel="stylesheet" type="text/css" href="css/styles.css">
    <!-- https://joaopereirawd.github.io/animatedModal.js/ modal -->
    <link rel="stylesheet" href="plugins/modal/animate.min.css">
    <!-- Google fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Cabin:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&display=swap"
        rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Kalam:wght@300;400;700&display=swap" rel="stylesheet">
    <!-- Font awesome -->
    <script src="https://kit.fontawesome.com/bf37eaf948.js" crossorigin="anonymous"></script>
</head>

<body>
    <!-------------------------- NAVIGATION ------------------------>
    <div id="mySidenav" class="snav">
        <!-- &times; = multiplication sign (kinda looks like an "x") -->
        <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">&times;</a>
        <a href="index.html">HOME</a>
        <a href="projects.html">PROJECTS</a>
        <a href="exp.html">EXPERIENCES</a>
        <!-- https://www.freecodecamp.org/news/how-to-use-html-to-open-link-in-new-tab/ -->
        <a href="docs/Karim, Arinah resume.pdf" target="_blank" rel="noopener noreferrer">RESUME</a>
        <a href="projects.html#contact" onclick="closeNav()">CONTACT</a>
    </div>

    <span class="menu-container">
        <!-- made it 3x so the menu text fits under it right -->
        <i class="fas fa-bars fa-3x" onclick="openNav()"></i>
    </span>
    <!----------------------- END OF NAVIGATION -------------------->


    <div id="opacity-change">
        <!-- button that takes user to top of page -->
        <!-- https://www.w3schools.com/howto/howto_js_scroll_to_top.asp -->
        <button onclick="topFunction()" id="myBtn" title="Go to top">Top</button>
        <header>
            <h1>Projects<br>
                <div class="typewriter-container">
                    <div class="typewriter">I've done interesting things in college.</div>
                </div>
                <br>
                <div>
                    <a href="projects.html#pro"><button class="hvr-pop" role="button">Explore!</button></a>
                </div>
            </h1>
            <!-- image by me -->
            <a href="index.html"><img src="images/logo.png" class="logo" alt="ANK logo"></a>
        </header>

        <article class="red" id="pro">
            <div class="container">
                <h3>Who's that Pokemon Trainer? It's ______!</h3>
                <div class="proj-flex">
                    <!-- image sauce:  https://www.kaggle.com/competitions/spaceship-titanic-->
                    <img src="images/pokemon.jpg" class="work-img" alt="Steven Stone Pokemon Battle">
                    <div class="proj-text">
                        <p>This was a <strong>Machine Learning</strong> semester project for my Usable Artificial Intelligence class that used <a
                                href="https://www.kaggle.com/datasets/rounakbanik/pokemon" class="hvr-sweep-to-top"
                                target="_blank" rel="noopener noreferrer">Kaggle's</a>
                            Pokemon csv which contained various information on Pokemon. The goal of this project was to
                            determine a non-playable character (NPC) trainer's class from the various found in the
                            Pokemon games. I worked with two other people and we worked collaboratively on manually
                            collecting
                            nearly 4000 trainer classes and their pokemon teams. My role on the team was coding the
                            project where I performed data cleaning and analysis using primarily Python and Pandas. In
                            the end, our model had a 46% accuracy, but this was expected as we did not have many samples
                            for some classes, or too many for others.

                            For more details, click <a id="pokeId" href="#pokeModal"
                                class="hvr-sweep-to-top">here</a>!</p>
                        <p>You can also check out our <a href="docs/uai.pdf" class="hvr-sweep-to-top" target="_blank"
                                rel="noopener noreferrer">written report</a> that discusses how
                            I cleaned data and showcases visualized information.</p>
                    </div>
                    <div id="pokeModal">
                        <!--THIS IS IMPORTANT! to close the modal, the class name has to match the name given on the ID -->
                        <div id="btn-close-modal" class="close-pokeModal">
                            &times;
                        </div>
                        <div class="modal-content">
                            <div class="container">
                                <!--Your modal content goes here-->
                                <article>
                                    <h2>Pokemon NPC Trainer Classifier</h2>
                                    <h3>Project Description</h3>
                                    <p>In the world of Pokemon games, there are various NPC trainers you can encounter.
                                        For our project, we built a classifier that attempted to determine a trainer
                                        class for a given pokemon team. In order to do this, I looked at various
                                        statistics of pokemon, such as their weight, height, attack, and other stats all
                                        found from the Kaggle file. We also needed a main file that contained the
                                        trainer class and their pokemon teams. This file was created manually by the
                                        whole team and because there were so many instances, we limited our game
                                        generations to look at to generations 1 through 4. I first preprocessed the data
                                        with simple text cleaning and removed
                                        classes that had not nearly enough instances to use in our model. I then had to
                                        determine how to represent the qualitative data as quantitative. Determining a
                                        model was difficult because of the varying team sizes, but the steps we took are
                                        elaborated further in the next section.</p>
                                </article>
                                <article>
                                    <h3>Methodology</h3>
                                    <p>Because we were working with textual data, I first needed to make sure all the
                                        <strong>text was cleaned</strong> and had the same formatting. In this case, everything was
                                        lowercased and possible spaces were removed. Spelling errors were common in our
                                        manually-created file so I created a function that would help me determine which
                                        rows had a spelling error. We then <strong>removed classes</strong> that had less than 10
                                        instances, which brought us from nearly 100 different classes to 52. We chose 10
                                        as it was the median for the number of instances of each trainer class.</p>
                                    <p>The next part was to vectorize the data. By <strong>vectorizing the data</strong>, we could
                                        convert our categorical data into numerical data. While it is pretty common for
                                        trainer classes to have specific themes, such as the Sailor class having only
                                        Water type pokemon, we also needed some other metric for classes that had
                                        varying distributions so that's why we used the Pokemon stats as well. I created
                                        a vectorizer function that would take an
                                        element type of a Pokemon and create a one-hot encoded elemental vector
                                        essentially. For the statistics, I created a vector that would contain the
                                        standard deviation of the pokemon statistics rather than the means because the
                                        standard deviation would represent the overall spread of the team. The
                                        <strong>statistics were normalized</strong> before this using mostly Power Transformer, but also
                                        Robust Scaler. </p>
                                </article>
                                <article>
                                    <h3>The Model</h3>
                                    <p>I wanted to implement a Recurrent Neural Network(RNN) for our project because it
                                        handles the varying lengths of pokemon teams well. The issue with the varying
                                        team lengths (the number of pokemon per team can range from 1 to 6) is that if
                                        we consider teams of just 1 pokemon and add padding to match the length of teams
                                        of 6, we lose valuable information. Using a neural network would help solve that
                                        problem. But unfortunately, my computer could not handle the model, so instead
                                        we did a <strong>LSTM machine learning model</strong> that would take a padded elemental vector
                                        and the statistics vector.
                                    </p>
                                    <p>
                                        First, the training and testing data were split into respective sets and were
                                        stratified according to the target variable (i.e., the trainer class) to ensure
                                        equal class distribution in both sets. Next, the input variables (team vectors
                                        and team statistics) and target variable (trainer class) were extracted from the
                                        training and testing data, respectively, and preprocessed for use in the model.
                                        The team vectors were padded using the `pad_sequences` function from TensorFlow.
                                        The reason why we did want to use MLP-RNN was to avoid having to pad the Team
                                        Vectors, but it was just unavoidable for us. The team statistics were flattened.
                                        The target variable was one-hot encoded using the `to_categorical` function from
                                        TensorFlow so we could convert it from strings to ints for the model. The model
                                        architecture is defined using Keras functional API. The model has two inputs,
                                        one for the team vectors and another for the team statistics, and one output for
                                        the trainer class. The team vectors input is passed through an LSTM layer with
                                        64 units. The resulting output is concatenated with the team statistics input.
                                        The concatenated output is then passed through three dense layers with ReLU
                                        activation functions and decreasing numbers of units (128, 64, and 32). The
                                        output was passed through a dense layer with 52 units and a softmax activation
                                        function to obtain the class probabilities. The model was compiled with Adam
                                        optimizer, categorical cross-entropy loss function, and accuracy metric. The
                                        model is trained on the training data using the `fit` method, with a batch size
                                        of 32, 10 epochs, and validation data consisting of the testing data. The
                                        training and validation metrics (loss and accuracy) were printed for each epoch
                                        too, which are featured in the Visualization section of the report (exit out of
                                        this pop-up to click on the report listed in the section if you're interested in
                                        more details!).

                                    </p>
                                </article>
                                <article>
                                    <h3>Conclusions</h3>
                                    <p>The accuracy of the model was quite poor: <strong>46.54%</strong>. However, there were various
                                        factors that could have contributed to such a low accuracy. We knew that padding
                                        the data would be an issue as there were many teams that had less than 6 pokemon
                                        in their team. Additionally, there may not have been enough data for some
                                        samples. Something else we could have tried to do is only keep classes with 20
                                        instances or higher. We also had classes that had much more samples than any
                                        other class. While we did attempt to stratify the trainer class target variable,
                                        it is possible that overfitting was indeed an issue.
                                    </p>
                                    <p>However, I'm still incredibly proud as this was a project I had not seen anywhere
                                        online. I first got into Computer Science because of how much I loved the
                                        Pokemon games and I was glad that my last school project combined my love for
                                        machine learning and Pokemon.</p>
                                </article>
                            </div>
                        </div>
                    </div>
                </div>
                <hr class="black">
                <h3>Optical Music Recognition</h3>
                <div class="proj-flex">
                    <!-- image sauce: my homework lol -->
                    <img src="images/omr.png" class="work-img" alt="musical notes labeled">
                    <div>
                        <p>This was an assignment for my Introduction to Computer Vision class. I worked collaboratively
                            with
                            two other students to see this assignment fulfilled. We utilized Python to implement
                            Computer Vision techniques to
                            accurately label music notes in a music sheet. To view a breakdown of our approach, click <a
                                id="omrId" href="#omrModal" class="hvr-sweep-to-top">here</a>!</p>
                    </div>
                    <div id="omrModal">
                        <!--THIS IS IMPORTANT! to close the modal, the class name has to match the name given on the ID -->
                        <div id="btn-close-modal" class="close-omrModal">
                            &times;
                        </div>
                        <div class="modal-content">
                            <div class="container">
                                <!--Your modal content goes here-->

                                <article>
                                    <h2>Optical Music Recognition</h2>
                                    <h3>Project Description</h3>
                                    <p>Given a music sheet, identify the pitch of a note using line detection and
                                        note recognition
                                        and produce a labeled music sheet.
                                    </p>
                                </article>
                                <article>
                                    <h3>Design Decisions and Assumptions</h3>
                                    <p>No note can be labeled as sharp or flat. All notes are assumed to be labeled
                                        as natural.
                                        All the staves will have a slope of 0 and be perfectly straight lines.
                                        Therefore when assigning names to notes, we use the y-axis to serve as a
                                        measure of distance as the determinant.
                                        The templates will be the same exact size as the notes it encounters in the
                                        music sheet. Therefore we did not resize the template or the music sheet.
                                    </p>
                                </article>
                                <article>
                                    <h3>Coding Classes and Functions</h3>
                                    <article class="omr-method">
                                        <h4>Convolution</h4>
                                        <p>We created a convolution function called <span
                                                class="italic">general_conv</span>. This function takes in
                                            three parameters: the image, the filter that it should be convolved
                                            with,
                                            and whether or not that filter is a template. The function, after
                                            determining whether we are doing convolution or cross-correlation flips
                                            the
                                            filter horizontally and vertically to make the filter a convolutional
                                            kernel. Then, two for loops are used to traverse through the image space
                                            and
                                            calculate the dot product of the kernel and image. The results are then
                                            sent
                                            to a function. The results are then stored in an image variable that
                                            is returned. Initially, we did not include the third parameter but we
                                            implemented it for our template matching algorithm.
                                        </p>
                                    </article>
                                    <article class="omr-method">
                                        <h4>Separable Convolution</h4>
                                        <p>For this, we created a function called <span class="italic">sep_conv</span>.
                                            It takes in three
                                            parameters: the image, an <span class="italic">H_x filter</span>, and an
                                            <span class="italic">H_y filter</span>. We make a call to
                                            <span class="italic">general_conv</span> and send in the image with one
                                            filter at a time and store the
                                            results in a variable that is returned.
                                        </p>
                                    </article>
                                    <article class="omr-method">
                                        <h4>Template Matching</h4>
                                        <p>We created a function <span class="italic">detect_template</span> which
                                            takes
                                            in two parameters: the
                                            image and the template. The template will contain the type of note that
                                            can
                                            be encountered in image (which is a music sheet). A cross-correlation is
                                            performed on the image with the template and the results being stored in
                                            score_image. Then we have a for loop that traverses over the image space
                                            and
                                            checks if, at a position in the image space, if there is a match with
                                            the
                                            template and image. We experimented with threshold values and used 0.7
                                            as it
                                            helped detect more true positives. There was an issue of values
                                            exceeding
                                            the 255 limit, so normalization had to be implmeneted.</p>
                                    </article>
                                    <article class="omr-method">
                                        <h4>Edge Map Scoring</h4>
                                        <p>For this problem, we created a function <span
                                                class="italic">sobel_edge_detector</span> which takes in an
                                            image and two filters. We performed the separable convolution on the
                                            image
                                            with the two filters and then computed the gradient magnitude and
                                            normalized
                                            it after to ensure that the gradient magnitude did not exceed 255.
                                            The function to calculate the edge match scores, we created a function
                                            called <span class="italic">score_func</span> that was inside of another
                                            function called <span class="italic">sobel_matching</span>.
                                            This algorithm utilizes the <span class="italic">sobel_edge_detection</span>
                                            function made earlier and
                                            calculates a score for the similarities. In our current implementation,
                                            it
                                            would take quite some time to compute the scoring matrix, but utilizing
                                            dynamic programming would definitely speed up the process.</p>
                                    </article>
                                    <article class="omr-method">
                                        <h4>Hough Space</h4>
                                        <p>The function we used
                                            for it is <span class="italic">hough_space</span>. With this function,
                                            we
                                            are able to determine the
                                            staff heights which helps with pitch detection. It also determines the
                                            locations of the staves. This function required a lot of tuning on the
                                            extrema detector. Generally, the more staves/more complexity the music
                                            has,
                                            the higher the neighborhood. It would probably make sense to establish
                                            the
                                            neighborhood as a function of the size of the image, but we did not do
                                            that.</p>
                                    </article>
                                    <article class="omr-method">
                                        <h4>Pitch Detection</h4>
                                        <p>The function we created for this is called <span
                                                class="italic">get_pitch</span>.
                                            To determine what note
                                            is on the staff, we determine what clef the notes on the staves are in.
                                            Then, based on the distance the note is away from the nearest staff, the
                                            note can be labeled by using the index of where the note is relative to
                                            the
                                            staves.</p>
                                    </article>
                                </article>
                                <article>
                                    <h3>Conclusions</h3>
                                    <p>The algorithm can identify the clefs correctly and can correctly name the
                                        notes for each respective cleff. It can also place the box around the
                                        notes. For improvements, we could have implemented a resizing
                                        method that would ensure that the template would be the appropriate size
                                        to convolve with. Our Edge Mapping function was quite slow, but if we
                                        used a dynamic programming approach, its time complexity would have
                                        significantly decreased.</p>
                                </article>
                            </div>
                        </div>
                    </div>
                </div>
                <hr class="black">
                <h3>Snake Game</h3>
                <div class="proj-flex">
                    <!-- image sauce:  https://www.kaggle.com/competitions/spaceship-titanic-->
                    <img src="images/snek.png" class="snek-img" alt="snake game">
                    <div>
                        <p>This was a final project for my Introduction to Artificial Intelligence class. I worked
                            collaboratively
                            with a group of four. We used Python and various libraries to create a Snake that would
                            learn to play
                            the game using BFS as a comparison to the Qlearning reinforcement algorithm.
                            For more details, click <a id="snekId" href="#snekModal" class="hvr-sweep-to-top">here</a>!
                        </p>
                        <p>For details about the algorithm and design, empirical analysis, or external resources, please
                            refer to
                            this <a href="docs/snake.pdf" class="hvr-sweep-to-top" target="_blank"
                                rel="noopener noreferrer">report</a>.
                        </p>
                    </div>
                    <div id="snekModal">
                        <!--THIS IS IMPORTANT! to close the modal, the class name has to match the name given on the ID -->
                        <div id="btn-close-modal" class="close-snekModal">
                            &times;
                        </div>
                        <div class="modal-content">
                            <div class="container">
                                <!--Your modal content goes here-->

                                <article>
                                    <h2>Snake Game</h2>
                                    <h3>Project Description</h3>
                                    <p>For our project, we decided to create the Snake game that will teach itself
                                        to
                                        pass through as many game levels as possible with reinforcement learning.
                                        The
                                        rules of the Snake game are to get the head of the “snake” to overlap the
                                        targeted
                                        square. The “snake” begins as a single square and gets one square longer for
                                        each targeted unit (the 'food') it overlaps, and the game ends when the
                                        snake
                                        hits a wall or into any part of itself. Once the targeted square is 'eaten',
                                        a new
                                        food unit will be randomly placed on the board while the snake stays in the
                                        same position, and the game will continue this process until it meets the
                                        ending
                                        game requirements. The main challenge is making sure the snake does not run
                                        into itself or the wall since more space will be occupied by the snake as it
                                        eats
                                        more food units which will leave less room for it to maneuver around the
                                        game
                                        board. The way that the AI chooses to move directly influences the future
                                        state
                                        of the game; for example, the board (represented by pixels/blocks), becomes
                                        occupied by the body of the snake over time. The path that the snake will
                                        have to take will be different depending on its size and the snake will have
                                        to
                                        recognize itself continuously. Additionally, since the food is generally
                                        randomly
                                        generated across the board, paths will have to be different depending on the
                                        randomization of the reward as well. Pixels do not support diagonal paths
                                        and
                                        rely on finding linear routes through corner turns so finding the corners to
                                        turn
                                        that minimize the risk of impact is important. We recreated the single
                                        player
                                        version of the game where the machine learns to play by utilizing Python and
                                        some of its libraries such as PyGame, numpy, random, pickle, queue and used
                                        a board of 200 x 250 pixels.</p>
                                </article>
                                <article>
                                    <h3>Solution as a Human Model</h3>
                                    <p>Our solution imitates the way a human would think through negative and posi-
                                        tive reinforcement. The AI is rewarded with points based on their actions.
                                        If the
                                        system hits the target it gains 10 points while it will lose 1 point for
                                        landing on
                                        empty space and lose 5 points for ending the game. The goal is for the game
                                        to
                                        get as many points as possible or the smallest negative number possible.
                                        Similar
                                        to a person, the AI tries to win by receiving a reward for what others deem
                                        as
                                        good actions, which in a human would initiate a positive response. Both the
                                        AI and a person are motivated by the reward so they would attempt to repeat
                                        the actions that earned them the points. Losing points would cause a similar
                                        reaction as well. Both the AI and a human will try to prevent losing points
                                        since
                                        they are punished for wrong actions. In doing so, both the computer and
                                        person
                                        would want to avoid the actions that would reduce their points or subtract
                                        from
                                        what they previously earned.</p>
                                </article>
                                <article>
                                    <h3>Conclusions & Improvements</h3>
                                    <p>All in all, the AI does adapt to its environment fairly quickly and does
                                        eventually
                                        learn how to get the food. However, trying to surpass 5 or 6 points would
                                        get
                                        more and more difficult almost exponentially as time goes on- the reason
                                        being
                                        that the snake's body would continue to grow and the way the algorithm
                                        adapts
                                        would be slow to avoid self collision, especially when near completion. In
                                        order
                                        to help alleviate the burden a higher level would cause, giving reward to
                                        having
                                        a larger amount of non-enclosed space would be a good way to ensure better
                                        future results. Non-enclosed space refers to the space that the snake does
                                        not
                                        cover with its body- by minimizing the space (by going in looping or closely
                                        knit
                                        patterns), the AI will be more efficient in solving the problems and
                                        eliminate
                                        some common defeats in the late stage game. All in all, we learned that
                                        while
                                        writing the initial game and learning algorithm was not difficult, getting
                                        the
                                        algorithm to give the snake the optimal chance of winning was difficult to
                                        fine-
                                        tune, and required forethought to the design of the game and the way that
                                        the
                                        AI would eventually learn to handle the board.
                                    </p>
                                </article>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </article>
        <footer id="contact">
            <div class="footer-flex">
                <div class="socials">
                    <a href="https://github.com/Mangosmoove" class="icon" target="_blank" rel="noopener noreferrer"><i
                            class="fa-brands fa-github fa-xl fa-inverse"></i></a>
                    <a href="https://www.linkedin.com/in/arinah-karim/" class="icon" target="_blank"
                        rel="noopener noreferrer"><i class="fa-brands fa-linkedin fa-xl fa-inverse"></i></a>
                </div>
                <div class="con">
                    <p>email: ankarim01@gmail.com</p>
                    <p>phone: (219) 232-5001</p>
                </div>
            </div>
        </footer>
    </div>


    <!------------------------------ JAVASCRIPT -------------------------------->
    <script src="js/nav.js"></script>
    <script src="js/top.js"></script>

    <script>
        const modal = document.querySelector(".modal");
        const trigger = document.querySelector(".trigger");
        const closeButton = document.querySelector(".close-button");

        function toggleModal() {
            modal.classList.toggle("show-modal");
        }

        function windowOnClick(event) {
            if (event.target === modal) {
                toggleModal();
            }
        }

        trigger.addEventListener("click", toggleModal);
        closeButton.addEventListener("click", toggleModal);
        window.addEventListener("click", windowOnClick); 
    </script>

    <script src="plugins/modal/jquery.min.js"></script>
    <script src="plugins/modal/animatedModal.js"></script>
    <script>


        $("#pokeId").animatedModal();
        $("#omrId").animatedModal();
        $("#snekId").animatedModal();
    </script>

</body>
